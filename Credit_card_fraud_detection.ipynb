{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YIFSqj9FmvtB",
        "outputId": "68e797e3-5756-47a6-e45b-cee1c97c2303"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18e2e445-86d0-4faf-9c87-d6d5b8fa7c25\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18e2e445-86d0-4faf-9c87-d6d5b8fa7c25\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving archive (4).zip to archive (4) (1).zip\n",
            "File 'archive (4) (1).zip' uploaded successfully. Now extracting...\n",
            "File 'archive (4) (1).zip' extracted to 'credit_card_data'.\n",
            "Dataset 'creditcard.csv' loaded successfully.\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Dataset information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n",
            "\n",
            "Missing values per column:\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Upload the zip file from your local machine\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Import the pandas library, which was missing\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# The key of the uploaded dictionary is the name of the file you selected\n",
        "uploaded_file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Extract the creditcard.csv file\n",
        "print(f\"File '{uploaded_file_name}' uploaded successfully. Now extracting...\")\n",
        "\n",
        "extraction_path = 'credit_card_data'\n",
        "if not os.path.exists(extraction_path):\n",
        "    os.makedirs(extraction_path)\n",
        "\n",
        "with zipfile.ZipFile(uploaded_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "print(f\"File '{uploaded_file_name}' extracted to '{extraction_path}'.\")\n",
        "\n",
        "# Step 3: Find and load the creditcard.csv file\n",
        "data_file_path = os.path.join(extraction_path, 'creditcard.csv')\n",
        "\n",
        "# Load the dataset using the correct function for CSV files\n",
        "try:\n",
        "    df = pd.read_csv(data_file_path)\n",
        "    print(\"Dataset 'creditcard.csv' loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file '{data_file_path}' was not found after extraction. Please check the contents of the zip file.\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while trying to read the CSV file: {e}\")\n",
        "    raise\n",
        "\n",
        "# Step 4: Data exploration and preparation\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset information:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSYwDZAJrrCz",
        "outputId": "5d16062d-73ff-45bb-a2b2-691c9f6104bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class distribution:\n",
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n",
            "Fraudulent transactions make up 0.1727% of the dataset.\n",
            "\n",
            "Data split into training and testing sets.\n"
          ]
        }
      ],
      "source": [
        "# Continue from the previous code block after it has successfully loaded the data.\n",
        "\n",
        "# Since the 'Class' column is what we are trying to predict, let's see its distribution\n",
        "# This will highlight the severe class imbalance\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['Class'].value_counts())\n",
        "print(f\"Fraudulent transactions make up {df['Class'].value_counts()[1]/len(df) * 100:.4f}% of the dataset.\")\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Remove 'Time' and 'Amount' columns, as they may not be useful for all models\n",
        "# and 'Amount' is not scaled like the other features (V1-V28)\n",
        "X = X.drop(['Time', 'Amount'], axis=1)\n",
        "# You might want to scale the 'Amount' feature instead of dropping it\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# X['scaled_amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\n",
        "# X = X.drop('Amount', axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"\\nData split into training and testing sets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zarmQ1llr06y",
        "outputId": "ce45035d-85ae-4167-b68c-aea34912b083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Baseline Random Forest Model Performance ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.93      0.83      0.88        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.97      0.91      0.94     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "F1 Score: 0.8757\n",
            "ROC-AUC Score: 0.9132\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "rf_baseline = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_baseline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_baseline = rf_baseline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"--- Baseline Random Forest Model Performance ---\")\n",
        "print(classification_report(y_test, y_pred_baseline))\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_baseline):.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_baseline):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrmMpuQ3txnF",
        "outputId": "dd1d3d07-3b7c-4b46-c0fd-1f0653e381d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Class Distribution After SMOTE ---\n",
            "Class\n",
            "0    227451\n",
            "1    227451\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Import the SMOTE library\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"--- Class Distribution After SMOTE ---\")\n",
        "print(y_res.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeKcROpTt7wi",
        "outputId": "74e19de1-ec54-411d-9c72-017807ef4308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Random Forest Model with SMOTE Performance ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.83      0.82      0.82        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.92      0.91      0.91     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "F1 Score: 0.8247\n",
            "ROC-AUC Score: 0.9080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:17:39] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- XGBoost Model with SMOTE Performance ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.69      0.85      0.76        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.85      0.92      0.88     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "F1 Score: 0.7615\n",
            "ROC-AUC Score: 0.9231\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Initialize and train the Random Forest model on the SMOTE data\n",
        "rf_smote = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_smote.fit(X_res, y_res)\n",
        "\n",
        "# Make predictions on the original (non-SMOTE) test set\n",
        "y_pred_rf_smote = rf_smote.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"\\n--- Random Forest Model with SMOTE Performance ---\")\n",
        "print(classification_report(y_test, y_pred_rf_smote))\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_rf_smote):.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_rf_smote):.4f}\")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Initialize and train the XGBoost model on the SMOTE data\n",
        "# The 'use_label_encoder=False' and 'eval_metric' are for avoiding warnings.\n",
        "xgb_smote = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
        "xgb_smote.fit(X_res, y_res)\n",
        "\n",
        "# Make predictions on the original test set\n",
        "y_pred_xgb_smote = xgb_smote.predict(X_test)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "print(\"\\n--- XGBoost Model with SMOTE Performance ---\")\n",
        "print(classification_report(y_test, y_pred_xgb_smote))\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_xgb_smote):.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_xgb_smote):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
